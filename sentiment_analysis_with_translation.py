# -*- coding: utf-8 -*-
"""Sentiment analysis with translation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wrg3C-6ftiExqNQUYgjMXroBSBjkCCWN
"""

pip install pandas nltk textblob

import nltk
nltk.download('vader_lexicon')

pip install vaderSentiment

pip install googletrans==4.0.0-rc1

from google.colab import drive

try:
  drive.mount('/content/drive')
except:
  print('Error mounting drive')


file_path_fb = '/content/drive/MyDrive/Colab Notebooks/XBOX/dataset_facebook-comments-scraper_2025-03-21_23-48-03-238.csv'
file_path_ig = '/content/drive/MyDrive/Colab Notebooks/XBOX/dataset_instagram-comment-scraper_2025-03-20_23-50-48-026.csv'
file_path_tt = '/content/drive/MyDrive/Colab Notebooks/XBOX/dataset_tiktok-comments-scraper_2025-03-21_00-45-33-528.csv'

df_1 = pd.read_csv(file_path_fb)
#df_2 = pd.read_csv(file_path_ig)
#df_3 = pd.read_csv(file_path_tt)

#Translate all columns from french to english and replace the column itself
import pandas as pd
from googletrans import Translator

def translate_text(text):
    """
    Translates text from French to English.

    Args:
        text (str): The text to translate.

    Returns:
        str: The translated text, or the original text if translation fails.
    """
    try:
        translator = Translator()
        translation = translator.translate(text, src='fr', dest='en')
        return translation.text
    except Exception as e:
        print(f"Translation error: {e}")
        return text  # Return the original text if translation fails


df_1['text'] = df_1['text'].astype(str).apply(translate_text)
#df_2['text'] = df_2['text'].astype(str).apply(translate_text)
#df_3['text'] = df_3['text'].astype(str).apply(translate_text)

#pd.to_csv(df_1)
#pd.to_csv(df_2)
#pd.to_csv(df_3)

import pandas as pd
import nltk

# ========== (A) If using NLTKâ€™s VADER ========== #
from nltk.sentiment.vader import SentimentIntensityAnalyzer
vader_analyzer = SentimentIntensityAnalyzer()

# ========== (B) If using TextBlob ========== #
from textblob import TextBlob

# --------------------------------------------------
# 1) LOAD THE DATA
# --------------------------------------------------
# Replace 'your_data.csv' with the path to your actual CSV.
# Because you showed a snippet with a lot of commas and possibly missing columns,
# you might need to adjust the 'sep' or 'quotechar' parameters if your CSV isn't standard.
#df_1 = pd.read_csv(file_path_fb)  # Use the correct path to your CSV file

# --------------------------------------------------
# 2) CLEAN/SELECT RELEVANT TEXT COLUMNS
# --------------------------------------------------
# In your sample, 'text' is where the comment content seems to be.
# If you have multiple text columns (like "replies/0/text" and "text"),
# you might unify them or handle them separately.

# For example, let's define a function that picks the "text" column if it exists,
# otherwise picks "replies/0/text", etc., as needed.

def extract_comment(row):
    # Attempt to read the 'text' column first
    comment_text = row.get("text", "")
    if not comment_text:
        # Fallback if there's no 'text' or it's empty
        comment_text = row.get("replies/0/text", "")
    return str(comment_text)  # ensure it's a string

# Create a new column "clean_text" with the extracted text
df_1["clean_text"] = df_1.apply(extract_comment, axis=1)
df_2["clean_text"] = df_2.apply(extract_comment, axis=1)
df_3["clean_text"] = df_3.apply(extract_comment, axis=1)
# --------------------------------------------------
# 3) PERFORM SENTIMENT ANALYSIS
# --------------------------------------------------
# ========== (A) Using VADER ========== #
def vader_sentiment_score(text):
    # text MUST be a string
    scores = vader_analyzer.polarity_scores(text)
    # 'compound' is the overall sentiment:
    # -1 (most negative) to +1 (most positive).
    return scores["compound"]

# Apply the function to each row in the "clean_text"
df_1["vader_compound_score"] = df_1["clean_text"].apply(vader_sentiment_score)
df_2["vader_compound_score"] = df_2["clean_text"].apply(vader_sentiment_score)
df_3["vader_compound_score"] = df_3["clean_text"].apply(vader_sentiment_score)

# ========== (B) Using TextBlob ========== #
def textblob_sentiment_score(text):
    analysis = TextBlob(text)
    return analysis.sentiment.polarity  # returns a float between -1.0 and +1.0

df_1["textblob_polarity"] = df_1["clean_text"].apply(textblob_sentiment_score)
df_2["textblob_polarity"] = df_2["clean_text"].apply(textblob_sentiment_score)
df_3["textblob_polarity"] = df_3["clean_text"].apply(textblob_sentiment_score)

# --------------------------------------------------
# 4) INSPECT OR EXPORT RESULTS
# --------------------------------------------------
# Now you have a DataFrame with new columns (like "vader_compound_score" or "textblob_polarity").
# You can inspect or filter the data in memory:
print(df_1[["clean_text", "vader_compound_score", "textblob_polarity"]].head())

# Finally, you can export back to CSV (including the new sentiment columns):
#df_1.to_csv("sentiment_output.csv", index=False)

# Assuming df has columns 'date' and sentiment scores from TextBlob and VADER
df_1["date"] = pd.to_datetime(df_1["date"])  # Ensure 'date' is in datetime format

# Group by month and calculate average sentiment scores
sentiment_trends_1 = df_1.groupby(df_1["date"].dt.to_period("M")).agg({
    "textblob_polarity": "mean",
    "vader_compound_score": "mean"
}).reset_index()

print(sentiment_trends_1)

# Assuming df has columns 'date' and sentiment scores from TextBlob and VADER
df_2["date"] = pd.to_datetime(df_2["date"])  # Ensure 'date' is in datetime format

# Group by month and calculate average sentiment scores
sentiment_trends_2 = df_2.groupby(df_2["date"].dt.to_period("M")).agg({
    "textblob_polarity": "mean",
    "vader_compound_score": "mean"
}).reset_index()

print(sentiment_trends_2)


# Assuming df has columns 'date' and sentiment scores from TextBlob and VADER
df_3["date"] = pd.to_datetime(df_3["date"])  # Ensure 'date' is in datetime format

# Group by month and calculate average sentiment scores
sentiment_trends_3 = df_3.groupby(df_3["date"].dt.to_period("M")).agg({
    "textblob_polarity": "mean",
    "vader_compound_score": "mean"
}).reset_index()

print(sentiment_trends_3)

#Percentage of Positive, Neutral, and Negative Comments

# Define categories for TextBlob
df_1["textblob_sentiment_category"] = df_1["textblob_polarity"].apply(
    lambda x: "Positive" if x > 0.2 else ("Negative" if x < -0.2 else "Neutral")
)
df_2["textblob_sentiment_category"] = df_2["textblob_polarity"].apply(
    lambda x: "Positive" if x > 0.2 else ("Negative" if x < -0.2 else "Neutral")
)
df_3["textblob_sentiment_category"] = df_3["textblob_polarity"].apply(
    lambda x: "Positive" if x > 0.2 else ("Negative" if x < -0.2 else "Neutral")
)

# Define categories for VADER
df_1["vader_sentiment_category"] = df_1["vader_compound_score"].apply(
    lambda x: "Positive" if x > 0.05 else ("Negative" if x < -0.05 else "Neutral")
)
df_2["vader_sentiment_category"] = df_2["vader_compound_score"].apply(
    lambda x: "Positive" if x > 0.05 else ("Negative" if x < -0.05 else "Neutral")
)
df_3["vader_sentiment_category"] = df_3["vader_compound_score"].apply(
    lambda x: "Positive" if x > 0.05 else ("Negative" if x < -0.05 else "Neutral")
)

# Calculate percentage of each category

textblob_kpi_1 = df_1["textblob_sentiment_category"].value_counts(normalize=True) * 100
vader_kpi_1 = df_1["vader_sentiment_category"].value_counts(normalize=True) * 100

textblob_kpi_2 = df_2["textblob_sentiment_category"].value_counts(normalize=True) * 100
vader_kpi_2 = df_2["vader_sentiment_category"].value_counts(normalize=True) * 100

textblob_kpi = df_3["textblob_sentiment_category"].value_counts(normalize=True) * 100
vader_kpi = df_3["vader_sentiment_category"].value_counts(normalize=True) * 100

print("TextBlob Sentiment Distribution:\n", textblob_kpi_2)
print("\nVADER Sentiment Distribution:\n", vader_kpi_2)

import re
import pandas as pd

def asignar_tema_multilingue(comentario):
    """Asigna un tema a un comentario en inglÃ©s o francÃ©s basado en palabras clave refinadas."""
    if not isinstance(comentario, str):
        return 'unknown/inconnu'

    comentario = comentario.lower()

    if re.search(r'(game pass|subscription|xbox live|xboxlive|online gaming|internet|fps|gamepass|abonnement|jeux en ligne|en ligne|internet|fps|xcloud|cloud gaming)', comentario):
        return 'game pass & online gaming'
    elif re.search(r'(console|hardware|graphics|performance|ram|processor|nvidia|4k|hd|display|controller|joystick|console|matÃ©riel|graphiques|performance|ram|processeur|nvidia|4k|hd|affichage|manette|joystick|m/k)', comentario):
        return 'hardware/features'
    elif re.search(r'(support|help|bugs|error|errors|debugging|support|aide|bogues|erreur|erreurs|dÃ©bogage|fix your captures app|fix the online)', comentario):
        return 'customer support'
    elif re.search(r'(ps 5|ps5|playstation5|nintendo|playstation|steam|pc|god of war|mario|mario kart|GTA|zelda|mortalk kombat|gay|ps5|playstation|nintendo|steam|pc|god of war|mario|zelda|superior console)', comentario):
        return 'console wars'
    elif re.search(r'(retro|remake|xbox|Xbox|Xbox 360|upcoming game|wait|game|gaming|videogames|playing|multiplayer|singleplayer|shooter|rpg|horror|adventure|action|jeu|jeux vidÃ©o|jouer|multijoueur|solo|tir|rpg|horreur|aventure|action|tony hawk|thps|avowed|halo|monster hunter|shredders|ssx|gamepass|warzone|cod|call of duty|ac:shadows)', comentario):
        return 'gaming'
    elif re.search(r'(meme|humor|joke|funny|drole|blague|comique|jaja|lol|xd|ðŸ¤£ðŸ¤£|ðŸ˜‚|ðŸ¤£|ðŸ¤¡|ðŸ¤®|poop|shitshow|nibbas|awoked|woke|trash)', comentario):
        return 'memes & humor'
    elif re.search(r'(marketing|advertising|anounce|campaign|cost|promotion|available|promo|buy|sale|ready|commercialisation|publicitÃ©|annonce|campagne|coÃ»t|promotion|disponible|promo|acheter|vente|prÃªt|pre-order|preorder|merch)', comentario):
        return 'marketing'
    elif re.search(r'(news|announcement|reveal|updates|nouvelles|annonce|rÃ©vÃ©lation|mises Ã  jour)', comentario):
        return 'news & announcements'
    else:
        return 'neutral conversation'


# Aplicar la funciÃ³n al DataFrame
df_1['tema_multilingue'] = df_1['text'].astype(str).apply(asignar_tema_multilingue)
df_2['tema_multilingue'] = df_2['text'].astype(str).apply(asignar_tema_multilingue)
df_3['tema_multilingue'] = df_3['text'].astype(str).apply(asignar_tema_multilingue)

# Imprimir los primeros 10 comentarios y sus temas para verificar
#print(df_1[['text', 'tema_multilingue']].head(10))

import pandas as pd
import matplotlib.pyplot as plt

def visualizar_temas_por_dataframe(dataframes, nombres):
    """Visualiza la distribuciÃ³n de temas en cada DataFrame."""
    for i, df in enumerate(dataframes):
        plt.figure(figsize=(10, 6))
        df['tema_multilingue'].value_counts().plot(kind='bar', color='skyblue')
        plt.title(f'Distribution of Topics on {nombres[i]}')
        plt.xlabel('Topic')
        plt.ylabel('Comment quantity')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

# Ejemplo de uso (reemplaza df1, df2, df3 con tus DataFrames y los nombres correspondientes)
dataframes = [df_1, df_2, df_3]  # Lista de tus DataFrames
nombres = ['Facebook', 'Instagram', 'Tiktok']  # Nombres para los grÃ¡ficos

visualizar_temas_por_dataframe(dataframes, nombres)

import pandas as pd
import matplotlib.pyplot as plt

def crear_grafico_sentimientos_apilado(df):
    """
    Crea un grÃ¡fico de barras apiladas para visualizar la polaridad por tema.
    """

    # Definir umbrales para polaridad
    umbral_positivo = 0.3
    umbral_negativo = -0.3

    # FunciÃ³n para clasificar la polaridad
    def clasificar_polaridad(polaridad):
        if polaridad > umbral_positivo:
            return 'positive'
        elif polaridad < umbral_negativo:
            return 'negative'
        else:
            return 'neutral'

    # Clasificar polaridad y agrupar por tema y polaridad
    df['sentimiento'] = df['textblob_polarity'].apply(clasificar_polaridad)
    grouped = df.groupby(['tema_multilingue', 'sentimiento']).size().unstack(fill_value=0)

    # Calcular porcentajes
    total = grouped.sum(axis=1)
    percentages = grouped.div(total, axis=0) * 100

    #Colores
    colores = {
        'positive': '#4CAF50',  # Verde
        'neutral': '#FFEB3B',   # Amarillo
        'negative': '#F44336'   # Rojo
    }

    # Crear grÃ¡fico de barras apiladas
    percentages.plot(kind='bar', stacked=True, figsize=(12, 8), color=[colores['negative'], colores['neutral'], colores['positive']])
    plt.title('Sentiment Analysis of Xbox Discussions on tiktok')
    plt.xlabel('Topics')
    plt.ylabel('Percentage of Sentiment')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

# Ejemplo de uso (reemplaza df1, df2, df3 con tus DataFrames y los nombres correspondientes)
#dataframes = [df_1, df_2, df_3]  # Lista de tus DataFrames
#nombres = ['Facebook', 'Instagram', 'Tiktok']  # Nombres para los grÃ¡ficos

crear_grafico_sentimientos_apilado(df_1)



df_1['text']

'''
#For any DOUBT ABOUT PHRASE
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Initialize VADER
analyzer = SentimentIntensityAnalyzer()

# Analyze the sentiment
text = "ran out of game pass"
vs = analyzer.polarity_scores(text)

# Print the compound score
print(f"Compound score: {vs['compound']}")

# Determine if the sentiment is positive or negative
if vs['compound'] > 0.3:
    print("The sentiment is positive.")
elif vs['compound'] < -0.3:
    print("The sentiment is negative.")
else:
    print("The sentiment is neutral.")
'''

#This bloq add more sensibility to the cathegorization adding filter of sarcasm

import re
import pandas as pd
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Inicializar VADER
analyzer = SentimentIntensityAnalyzer()

# Lista de palabras y frases sarcÃ¡sticas (puedes modificarla)
sarcasm_keywords = [
    "yeah right", "oh great", "just what I needed", "love it when",
    "totally", "sure", "amazing...", "fantastic", "wonderful", "of course",
    "obviously", "brilliant", "what a surprise", "superb", "so much fun"
]

# Ajuste para penalizar sarcasmo en VADER (puedes cambiarlo)
sarcasm_penalty = 0.5  # Reduce el valor de sentimiento para comentarios sarcÃ¡sticos

def detect_sarcasm(comentario):
    """Detecta sarcasmo en un comentario basado en palabras clave."""
    if not isinstance(comentario, str):
        return False
    comentario = comentario.lower()
    return any(pattern in comentario for pattern in sarcasm_keywords)

def vader_sentiment_adjusted(comentario, is_sarcastic):
    """Aplica VADER y ajusta el puntaje si el comentario es sarcÃ¡stico."""
    sentiment = analyzer.polarity_scores(comentario)['compound']

    if is_sarcastic:
        return sentiment - sarcasm_penalty  # Penaliza el sarcasmo
    return sentiment

def asignar_tema_multilingue(comentario):
    """Asigna un tema a un comentario en inglÃ©s o francÃ©s basado en palabras clave refinadas."""
    if not isinstance(comentario, str):
        return 'unknown/inconnu'

    comentario = comentario.lower()

    if detect_sarcasm(comentario):
        return 'sarcasm'
    elif re.search(r'(game pass|subscription|xbox live|xboxlive|online gaming|internet|fps|gamepass|abonnement|jeux en ligne|en ligne|internet|fps|xcloud|cloud gaming)', comentario):
        return 'game pass & online gaming'
    elif re.search(r'(console|hardware|graphics|performance|ram|processor|nvidia|4k|hd|display|controller|joystick|console|matÃ©riel|graphiques|performance|ram|processeur|nvidia|4k|hd|affichage|manette|joystick|m/k)', comentario):
        return 'hardware/features'
    elif re.search(r'(support|help|bugs|error|errors|debugging|support|aide|bogues|erreur|erreurs|dÃ©bogage|fix your captures app|fix the online)', comentario):
        return 'customer support'
    elif re.search(r'(ps 5|ps5|playstation5|nintendo|playstation|steam|pc|god of war|mario|mario kart|GTA|zelda|mortalk kombat|gay|ps5|playstation|nintendo|steam|pc|god of war|mario|zelda|superior console)', comentario):
        return 'console wars'
    elif re.search(r'(retro|remake|xbox|Xbox|Xbox 360|upcoming game|wait|game|gaming|videogames|playing|multiplayer|singleplayer|shooter|rpg|horror|adventure|action|jeu|jeux vidÃ©o|jouer|multijoueur|solo|tir|rpg|horreur|aventure|action|tony hawk|thps|avowed|halo|monster hunter|shredders|ssx|gamepass|warzone|cod|call of duty|ac:shadows)', comentario):
        return 'gaming'
    elif re.search(r'(meme|humor|joke|funny|drole|blague|comique|jaja|lol|xd|ðŸ¤£ðŸ¤£|ðŸ˜‚|ðŸ¤£|ðŸ¤¡|ðŸ¤®|poop|shitshow|nibbas|awoked|woke|trash)', comentario):
        return 'memes & humor'
    elif re.search(r'(marketing|advertising|anounce|campaign|cost|promotion|available|promo|buy|sale|ready|commercialisation|publicitÃ©|annonce|campagne|coÃ»t|promotion|disponible|promo|acheter|vente|prÃªt|pre-order|preorder|merch)', comentario):
        return 'marketing'
    elif re.search(r'(news|announcement|reveal|updates|nouvelles|annonce|rÃ©vÃ©lation|mises Ã  jour)', comentario):
        return 'news & announcements'
    else:
        return 'neutral conversation'

# Aplicar la funciÃ³n al DataFrame
for df in [df_1, df_2, df_3]:
    df['is_sarcastic'] = df['text'].astype(str).apply(detect_sarcasm)  # Detecta sarcasmo
    df['tema_multilingue'] = df['text'].astype(str).apply(asignar_tema_multilingue)  # Asigna tema
    df['vader_sentiment'] = df.apply(lambda row: vader_sentiment_adjusted(row['text'], row['is_sarcastic']), axis=1)  # Ajusta VADER

# Imprimir los primeros 10 comentarios y sus datos
print(df_1[['text', 'tema_multilingue', 'is_sarcastic', 'vader_sentiment']].head(10))

df_1.describe()

